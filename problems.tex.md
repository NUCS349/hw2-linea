## Problems

## Code implementation (5 points)
Pass test cases by implementing the functions in the `code` directory.

Your grade for this section is defined by the autograder. If it says you got an 80/100,
you get 4 points here.

## Free response questions (5 points)

Answer the following free response questions in a separate document, 
saved as a .pdf and **uploaded to Canvas**.

#### 1. (0.5 point) Use the function you implemented `generate_regression_data` to generate clean data (`amount_of_noise` = 0) from polynomial functions of the following degrees: {2,4}. For each degree, generate 50 points. For each of the 2 datasets you generated:
   - A. Run your implementation of `PolynomialRegression` using degree {1,2,4,8}
   - B. Create one plot for that dataset that shows mean squared error of your regression as a function of degree. Make degree the horizontal dimension and error the vertical dimension.  Note: you must indicate the degree of polynomial used to GENERATE the data at the top of the plot, as well as indicating the degree of polynomial used to FIT the data along the horizontal access.

#### 2. (0.5 point) Repeat exactly what you did in question 1, but when generating data, add noise (`amount_of_noise` = 0.2). 

#### 3. (0.5 points) Given your plots from question 1 and 2, describe the relationship of the error to the degree of poynomial used to generate the data originally and the degree of polynomial used to fit the data. How does this change as the amount of noise changes.

#### 4. (0.5 points) Use the noisy dataset you generated from a 4th degree polynomial. Show a scatter plot of the dataset. Indicate the degree of the polynomial used to generate it in the title of the plot. Plot 3 functions learned with`PolynomialRegression` over the scatter plot: 
   - a functioned learned by a lower degree (e.g. 1 or 2) polynomial regression
   - a function learned by the same degree (i.e. learned with a 4th degree polynomial)
   - a function learned by a polynomial with a higher degree than 4 that generated the lowest error

#### 5. (0.5 points) Given your plots from the previous questions is it a good idea to fit the data with the highest degree polynomial available? Why or why not? I suggest phrasing your answer in terms of bias vs variance and underfitting and overfitting.

#### 6. (0.5 points) Explain how to do linear classification via linear regression. Be clear. Use a graph to illustrate how it works. This graph doesn't need to be generated by your code, but it must be clearly labeled and made by you (not cut and pasted from somewhere). Explain one key weakness of classification via regression. Be clear. Perhaps illustrate this point, as well, with your graph.

#### 7.(1 point) In the data directory, we provide 5 datasets as json files: blobs, circles, crossing, parallell_lines and transform_me. For each of these 5 provided datasets (mentioned above), generate a scatter plot of the data with your own code. Color each point according to its true class. Plot the linear separator learned by your perceptron on top of the scatter plot, for each data set. If the perceptron never converged on a final line, pick the line it had generated by the time it reached max_iterations. See the source for`load_json_data` for an example of how to plot a scatterplot. Using http://https://matplotlib.org is encouraged.  

(Aside: you can upload the json files containing the datasets to http://ml-playground.com/ to see how different learning algorithms work on each dataset. This is not required for points, and you're definitely not allowed to submit scatter plots built by ml-playground, but it might be illuminating and useful for checking your work).

#### 8. (0.5 points) For each of the 5 datasets, say whether your perceptron successfuly separate the two classes on this dataset? Explain why or why not. 

#### 9. (0.5 points) In `code/perceptron.py`, you passed a test case by implementing the function `transform_data`. Describe the transformation you made to the input data to pass the test case. Explain how it allowed you to pass the test case (i.e. how did the change made to the data enable the system to do what it could not previously do?).



 


 
